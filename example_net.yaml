# Section that defines the dataset files.
dataset:
  # Training file, used for training the network.
  training: dataset/training.tfrecord
  # Validation file, used to inspect progress of the network as it is training.
  # It is also used as the source for progress images.
  validation: dataset/validation.tfrecord
  # Test dataset, used for performing final evaluations on the performance of the network.
  testing: dataset/testing.tfrecord

# The geometry of the object we are detecting in the visual mesh.
geometry:
  # How many intersections with the target object we should have.
  intersections: 6
  # How many intersections the mesh can vary by before it will generate a new mesh
  intersection_tolerance: 0.5
  # How many distinct meshes to cache before dropping old ones
  cached_meshes: 100
  # The maximum distance the visual mesh will be projected for. This should be slightly further than the most distant
  # object that you wish to detect to account for noises in the projection.
  max_distance: 20
  # The radius of the object to be detected.
  radius: 0.0949996
  # The shape to project, either CIRCLE or SPHERE.
  shape: SPHERE

# Configuration for the convolutional neural network.
network:
  # The structure of the network is defined by this list of lists.
  # Each list element corresponds to a neural network after a convolution.
  # For example a network structure of [[2], [2]] would have two convolutional layers with two single layer networks
  # after each convolution with an output size of 2.
  # Having an empty list (e.g.) [[], [2]] would correspond to two stacked convolutions.
  # The final layer of the network is always equal to the number of classes and should be omitted, typically by an
  # empty list.
  structure:
    [[16], [16], [16], [16], [16], [16], [16], [8], [8], [8], [8], [8], []]
  # Activation Function
  activation_fn: selu
  # This is a mapping of the classes to the colours that represent them in the mask images.
  # Each of the elements has a name, and an RGB value that stores it in the mask image.
  # The index of the final output layer will be the same as the order provided in this list.
  classes:
    - [ball, [255, 0, 0]]
    - [goal, [255, 255, 0]]
    - [line, [255, 255, 255]]
    - [field, [0, 255, 0]]
    - [environment, [0, 0, 0]]

# Testing
testing:
  # How many raw elements to process at a time during testing
  batch_size: 200
  # The number of bins to use when calculating the PR curve
  num_bins: 1000

# Settings to use when training the network
training:
  # The batch size to use when training the network (how many images to feed in a single training step).
  # Do not make this number too large or it will create poor gradients.
  batch_size: 20
  # Number of batches to consider an epoch, if None then it is the length of the input dataset
  batches_per_epoch: 1000
  # Number of epochs to execute
  epochs: 100

  # Settings for the validation step of the network.
  validation:
    # How big the batch should be for validation step.
    batch_size: 20
    # How many batches to load for the validation step
    samples: 10
    # How many images to show in tensorboard, they are taken as the first n images of the validation set.
    progress_images: 20

  # Variations to apply to the training data, note this only applies to training data and not validation.
  # They are defined using a mean value and a standard deviation using a truncated normal distribution.
  # If the values are greater than 2 standard deviations from the mean they will be resampled.
  variants:
    mesh:
      # Adjustments to the height of the mesh above the observation plane.
      height: { "mean": 0, "stddev": 0.05 }
      # Adjustments to the orientation of the observation plane.
      # This value is used for three euler rotations added to the camera rotation in radians.
      rotation: { "mean": 0, "stddev": 0.0872665 }
