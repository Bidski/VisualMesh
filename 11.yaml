# Section that defines the dataset files.
dataset:
  # Training file, used for training the network.
  training: training.tfrecord
  # Validation file, used to inspect progress of the network as it is training.
  # It is also used as the source for progress images.
  validation: validation.tfrecord
  # Test dataset, used for performing final evaluations on the performance of the network.
  test: test.tfrecord

# The geometry of the object we are detecting in the visual mesh.
geometry:
  # How many intersections with the target object we should have.
  intersections: 4
  # The maximum distance the visual mesh will be projected for. This should be slightly further than the most distant
  # object that you wish to detect to account for noises in the projection.
  max_distance: 15
  # The radius of the object to be detected.
  radius: 0.075
  # The shape to project, either CYLINDER, CIRCLE or SPHERE.
  shape: SPHERE
  # The height of the cylinder, only used for the cylinder geometry.
  # height: 1

# Configuration for the convolutional neural network.
network:
  # The structure of the network is defined by this list of lists.
  # Each list element corresponds to a neural network after a convolution.
  # For example a network structure of [[2], [2]] would have two convolutional layers with two single layer networks
  # after each convolution with an output size of 2.
  # Having an empty list (e.g.) [[], [2]] would correspond to two stacked convolutions.
  # The final layer of the network is always equal to the number of classes and should be omitted, typically by an
  # empty list.
  structure: [[4], [4], [4], [4], [4], [4], [4], [4], [4], [4], []]
  # This is a mapping of the classes to the colours that represent them in the mask images.
  # Each of the elements has a name, and an RGB value that stores it in the mask image.
  # The index of the final output layer will be the same as the order provided in this list.
  classes:
    - [ball, [255, 255, 255]]
    - [environment, [0, 0, 0]]

# Settings to use when training the network
training:
  # The number of epochs to train for (number of times to loop through the training data).
  # Note that if you restart the training, it will loose track of how many epochs it has done so far.
  epochs: 5
  # The batch size to use when training the network (how many images to feed in a single training step).
  # Do not make this number too large or it will create poor gradients.
  batch_size: 5
  # The learning rate for the Adam optimiser.
  learning_rate: 0.001
  # The size of the buffer used for shuffling the input data.
  shuffle_size: 1000
  # How many batches between saving the progress of the network.
  save_frequency: 250

  # Settings for the tutor network.
  tutor:
    # The learning rate for the tutor network.
    # This value does not decay as the tutor network is not designed to converge.
    learning_rate: 0.1
    # The hysteresis threshold for training in the tutor network.
    # When the tutor network starts to get close to a convergent point, it will have many small gradients that
    # don't help the tutor network do it's job of finding error points. Having a hysteresis value here that
    # ignores small errors will make the larger errors have a greater impact in the training of the tutor.
    threshold: 0.05
    # The base weight to add to all outputs so that points can't get to 0 weight
    base_weight: 0.05
    # This allows the tutor to have a different structure than the main network.
    # If this isn't set, the structure of the tutor will be identical to that of the main network.
    structure: [[8], [8], [8], [8], [8], [8], [8], [8], [8], [8], []]

  # Settings for the validation step of the network.
  validation:
    # How big the batch should be for validation step.
    batch_size: 200
    # How many images to show in tensorboard, they are taken as the first n images of the validation set.
    progress_images: 10
    # How often to perform a validation step.
    frequency: 50
    # How often to update the progress images.
    image_frequency: 250

  # Variations to apply to the training data, note this only applies to training data and not validation.
  # They are defined using a mean value and a standard deviation using a truncated normal distribution.
  # If the values are greater than 2 standard deviations from the mean they will be resampled.
  variants:
    image:
      # Image brightness adjustment.
      brightness: { 'mean': 0, 'stddev': 0.0 }
      # Image contrast adjustment.
      contrast: { 'mean': 0, 'stddev': 0.0 }
      # Image saturation adjustment.
      saturation: { 'mean': 0, 'stddev': 0.0 }
      # Image gamma adjustment (make sure this value is always positive).
      gamma: { 'mean': 1, 'stddev': 0.0 }
      # Image hue adjustment.
      hue: { 'mean': 0, 'stddev': 0.0 }
    mesh:
      # Adjustments to the height of the mesh above the observation plane.
      height: { 'mean': 0, 'stddev': 0.0 }
      # Adjustments to the orientation of the observation plane.
      # This value is used as three componentwise euler rotations added to the initial rotation in radians.
      rotation: { 'mean': 0, 'stddev': 0.0 }
